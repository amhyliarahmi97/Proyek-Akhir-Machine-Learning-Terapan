# -*- coding: utf-8 -*-
"""Proyek-Akhir-Machine-Learning-Terapan2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-698XVBfMfI4aeBzzlQ4ifIVXxQDzSSJ

# ðŸ“˜ Laporan Proyek: Sistem Rekomendasi Buku

---
By : Rahmi Amilia

### 1. Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics.pairwise import cosine_similarity
from scipy.sparse import csr_matrix

import warnings
warnings.filterwarnings("ignore")

"""### 2. Load Dataset"""

books = pd.read_csv('/content/BX_Books.csv', sep=';', encoding='latin-1', nrows=10000)
ratings = pd.read_csv("/content/BX-Book-Ratings.csv", sep=';', encoding='latin-1', on_bad_lines='skip')
users = pd.read_csv("/content/BX-Users.csv", sep=';', encoding='latin-1', on_bad_lines='skip')

"""### 3. Data Understanding

Dataset terdiri dari:
- books.csv: 10.000 baris, 8 kolom
- ratings.csv: 1.149.780 baris, 3 kolom
- users.csv: 278.858 baris, 3 kolom

Fitur penting:
- `isbn`, `title`, `author`, `year`, `publisher`, `image_s/m/l`
- `user_id`, `location`, `age`
- `rating` (0-10)

> Kolom `age` memiliki missing values dan outlier seperti usia <5 atau >100.
"""

print('jumlah data books : ', books.shape)
print('jumlah data ratings : ', ratings.shape)
print('jumlah data users : ', users.shape)

ratings.columns = ["user_id", "isbn", "rating"]
ratings.head()

books.columns = ["isbn", "title", "author", "year", "publisher", "image_s", "image_m", "image_l"]
books.head()

users.columns = ["user_id", "location", "age"]
users.head()

"""Kolom-kolom pada dataset books:

* ***ISBN*** : ID unik buku (International Standard Book Number).

* ***TITLE*** : Judul buku.

* ***AUTHOR*** : Nama penulis buku.

* ***YEAR*** : Tahun publikasi buku.

* ***PUBLISHER*** : Penerbit buku.

* image_s, image_m, image_l: URL gambar sampul buku dalam ukuran kecil, sedang, dan besar (tidak digunakan dalam modeling).
"""

books.info()
books.describe(include='all')

"""Kolom-kolom pada dataset users:

* ***user_id*** : ID unik pengguna.

* ***location*** : Lokasi pengguna (biasanya dalam format kota, negara bagian, negara).

* ***age*** : Usia pengguna.
"""

users.info()
users.describe()

"""Kolom-kolom pada dataset ratings:

* user_id : ID pengguna.

* isbn : ID buku.

* rating : Nilai rating dari pengguna terhadap buku. Nilai 0 menunjukkan rating implisit (belum memberikan penilaian eksplisit).
"""

ratings.info()
ratings['rating'].value_counts().sort_index()

"""### 4. Data Preparation

### 4.1 Rename Kolom
4.2 Hapus Duplikat ISBN
"""

books.drop_duplicates(subset='isbn', keep='first', inplace=True)

"""4.3 Filter Buku dengan Tahun Tidak Masuk Akal"""

books = books[(books['year'] >= 1900) & (books['year'] <= 2025)]

"""4.4 Hapus Kolom Gambar"""

books.drop(columns=['image_s', 'image_m', 'image_l'], inplace=True)

"""4.5 Filter Rating Eksplisit"""

ratings = ratings[ratings['rating'] > 0]

"""### 5. Modeling & Results

5.1 Collaborative Filtering (SVD)

* Menggunakan Surprise library untuk menerapkan SVD.

* Melatih model menggunakan data eksplisit.

* Memberikan rekomendasi Top-N buku untuk user tertentu.
"""

!pip install scikit-surprise --no-binary scikit-surprise

!pip install numpy==1.23.5

from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split
from surprise.accuracy import rmse

# Membaca data ratings
reader = Reader(rating_scale=(1, 10))
data = Dataset.load_from_df(ratings[['user_id', 'isbn', 'rating']], reader)

# Split data
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Buat model SVD
svd_model = SVD()
svd_model.fit(trainset)

# Prediksi dan evaluasi
predictions = svd_model.test(testset)
rmse(predictions)

"""5.2 Contoh Output Rekomendasi SVD

Membuat fungsi rekomendasi untuk user tertentu:
"""

def recommend_books_svd(user_id, books_df, ratings_df, model, n=5):
    user_books = ratings_df[ratings_df['user_id'] == user_id]['isbn'].tolist()
    unread_books = books_df[~books_df['isbn'].isin(user_books)]

    predictions = []
    for isbn in unread_books['isbn']:
        pred = model.predict(user_id, isbn)
        predictions.append((isbn, pred.est))

    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]
    return books_df[books_df['isbn'].isin([isbn for isbn, _ in top_n])][['title', 'author']]

recommend_books_svd(user_id=276729, books_df=books, ratings_df=ratings, model=svd_model)

"""5.3 Content-Based Filtering

* Gunakan fitur title dan author dari buku.

* Ubah menjadi vektor TF-IDF.

* Hitung Cosine Similarity antar buku.

* Berikan rekomendasi untuk buku tertentu.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Ganti NaN dengan string kosong
books['title'] = books['title'].fillna('')
books['author'] = books['author'].fillna('')

# Gabungkan fitur
books['combined_features'] = books['title'] + ' ' + books['author']

# TF-IDF dan Cosine Similarity
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(books['combined_features'])

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

"""Contoh Output Rekomendasi Content-Based"""

def get_recommendations(title, books_df, cosine_sim, n=5):
    from difflib import get_close_matches
    import numpy as np
    import pandas as pd

    indices = pd.Series(books_df.index, index=books_df['title']).drop_duplicates()

    if title not in indices:
        closest = get_close_matches(title, books_df['title'], n=1)
        if not closest:
            return "Judul tidak ditemukan, dan tidak ada kemiripan yang cukup."
        else:
            title = closest[0]
            print(f"Menampilkan hasil rekomendasi untuk judul terdekat: '{title}'")

    idx = indices[title]
    sim_vector = cosine_sim[idx]
    if hasattr(sim_vector, 'toarray'):
        sim_vector = sim_vector.toarray().flatten()
    else:
        sim_vector = np.array(sim_vector).flatten()

    sim_scores = list(enumerate(sim_vector))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:n+10]
    book_indices = [i[0] for i in sim_scores if i[0] < len(books_df)]

    return books_df.iloc[book_indices[:n]][['title', 'author']]

recommendations = get_recommendations("Harry Potter and the Chamber of Secrets (Book 2)", books, cosine_sim)
print(recommendations)

from difflib import get_close_matches
get_close_matches("Harry Potter and the Chamber of Secrets", books['title'], n=5)

"""### 6. Evaluation

6.1 Evaluasi Collaborative Filtering (SVD)

Metrik: RMSE (Root Mean Squared Error)
RMSE mengukur seberapa jauh hasil prediksi model terhadap nilai rating aktual. Nilai RMSE lebih kecil berarti lebih baik.
"""

from surprise import accuracy

rmse_score = accuracy.rmse(predictions)

"""Metrik Tambahan: Precision@K dan Recall@K

Metrik ini digunakan untuk mengevaluasi seberapa relevan hasil rekomendasi bagi user. Kita gunakan K = 5.
"""

from collections import defaultdict

def precision_recall_at_k(predictions, k=5, threshold=7):
    user_est_true = defaultdict(list)
    for uid, _, true_r, est, _ in predictions:
        user_est_true[uid].append((est, true_r))

    precisions = {}
    recalls = {}

    for uid, user_ratings in user_est_true.items():
        user_ratings.sort(key=lambda x: x[0], reverse=True)
        top_k = user_ratings[:k]

        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)
        n_rec_k = sum((est >= threshold) for (est, _) in top_k)
        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in top_k)

        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0
        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0

    avg_precision = sum(prec for prec in precisions.values()) / len(precisions)
    avg_recall = sum(rec for rec in recalls.values()) / len(recalls)

    return avg_precision, avg_recall

precision, recall = precision_recall_at_k(predictions, k=5)
print(f"Precision@5: {precision:.4f}")
print(f"Recall@5: {recall:.4f}")